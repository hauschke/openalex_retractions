{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to retraction_metadata_100.csv\n",
      "Exported to retraction_metadata_200.csv\n",
      "Exported to retraction_metadata_300.csv\n",
      "Exported to retraction_metadata_400.csv\n",
      "Exported to retraction_metadata_500.csv\n",
      "Exported to retraction_metadata_600.csv\n",
      "Exported to retraction_metadata_700.csv\n",
      "Exported to retraction_metadata_800.csv\n",
      "Exported to retraction_metadata_900.csv\n",
      "Exported to retraction_metadata_1000.csv\n",
      "Exported to retraction_metadata_1100.csv\n",
      "Exported to retraction_metadata_1200.csv\n",
      "Exported to retraction_metadata_1300.csv\n",
      "Exported to retraction_metadata_1400.csv\n",
      "Exported to retraction_metadata_1500.csv\n",
      "Exported to retraction_metadata_1600.csv\n",
      "Exported to retraction_metadata_1700.csv\n",
      "Exported to retraction_metadata_1800.csv\n",
      "Exported to retraction_metadata_1900.csv\n",
      "Exported to retraction_metadata_2000.csv\n",
      "Exported to retraction_metadata_2100.csv\n",
      "Exported to retraction_metadata_2200.csv\n",
      "Exported to retraction_metadata_2300.csv\n",
      "Exported to retraction_metadata_2400.csv\n",
      "Exported to retraction_metadata_2500.csv\n",
      "Exported to retraction_metadata_2600.csv\n",
      "Exported to retraction_metadata_2700.csv\n",
      "Exported to retraction_metadata_2800.csv\n",
      "Exported to retraction_metadata_2900.csv\n",
      "Exported to retraction_metadata_3000.csv\n",
      "Exported to retraction_metadata_3100.csv\n",
      "Exported to retraction_metadata_3200.csv\n",
      "Exported to retraction_metadata_3300.csv\n",
      "Exported to retraction_metadata_3400.csv\n",
      "Exported to retraction_metadata_3500.csv\n",
      "Exported to retraction_metadata_3600.csv\n",
      "Exported to retraction_metadata_3700.csv\n",
      "Exported to retraction_metadata_3800.csv\n",
      "Exported to retraction_metadata_3900.csv\n",
      "Exported to retraction_metadata_4000.csv\n",
      "Exported to retraction_metadata_4100.csv\n",
      "Exported to retraction_metadata_4200.csv\n",
      "Exported to retraction_metadata_4300.csv\n",
      "Exported to retraction_metadata_4400.csv\n",
      "Exported to retraction_metadata_4500.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Function to fetch JSON on update-nature\n",
    "def fetch_update_nature(doi):\n",
    "    url = f\"https://api.labs.crossref.org/works/{doi}?mailto=christian.hauschke@tib.eu\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json()\n",
    "        updates = json_data.get('message', {}).get('cr-labs-updates', [])\n",
    "        return \";\".join([update.get('update-nature') for update in updates])\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Read CSV file and start from specified line/DOI\n",
    "csv_filename = \"OpenAlex_retractions.csv\"\n",
    "start_line = 0  # Set to the line number/DOI from which to start\n",
    "batch_size = 100\n",
    "openalexexport_df = pd.read_csv(csv_filename, skiprows=range(1, start_line), nrows=batch_size)\n",
    "\n",
    "# Extend DataFrame with update_nature column\n",
    "openalexexport_df['update_nature'] = openalexexport_df['doi'].apply(fetch_update_nature)\n",
    "\n",
    "# Export CSV file every 1500 DOIs\n",
    "while not openalexexport_df.empty:\n",
    "    export_filename = f\"retraction_metadata_{start_line + len(openalexexport_df)}.csv\"\n",
    "    openalexexport_df.to_csv(export_filename, index=False)\n",
    "    print(f\"Exported to {export_filename}\")\n",
    "    time.sleep(2)  # Wait for 2 seconds before exporting next batch\n",
    "    start_line += batch_size\n",
    "    openalexexport_df = pd.read_csv(csv_filename, skiprows=range(1, start_line), nrows=batch_size)\n",
    "    openalexexport_df['update_nature'] = openalexexport_df['doi'].apply(fetch_update_nature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each CSV file and merge data\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(directory, csv_file))\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# Export the merged DataFrame to a single CSV file\n",
    "merged_filename = \"merged_retraction_metadata.csv\"\n",
    "merged_df.to_csv(merged_filename, index=False)\n",
    "\n",
    "print(f\"Merged data exported to {merged_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
